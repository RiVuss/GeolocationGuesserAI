{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import reverse_geocoder as rg\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "from torchvision import io\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = 'Streetview_Image_Dataset/'\n",
    "DATA_PATH = SOURCE + 'raw/'\n",
    "\n",
    "CSV_NAME = 'coordinates.csv'\n",
    "OUTPUT_PATH = SOURCE + 'processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.824885</td>\n",
       "      <td>-98.499517</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.451752</td>\n",
       "      <td>-54.563937</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23.496464</td>\n",
       "      <td>-47.460542</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.548678</td>\n",
       "      <td>-72.852778</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35.010870</td>\n",
       "      <td>140.064397</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude image_name\n",
       "0  20.824885  -98.499517      0.png\n",
       "1  -3.451752  -54.563937      1.png\n",
       "2 -23.496464  -47.460542      2.png\n",
       "3 -16.548678  -72.852778      3.png\n",
       "4 -35.010870  140.064397      4.png"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column_names = [\"latitude\", \"longitude\"]\n",
    "df = pd.read_csv(DATA_PATH + CSV_NAME,)\n",
    "df['image_name'] = df.index.astype('str') + '.png'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Helper functions for offline country/continent lookups\n",
    "# ---------------------------\n",
    "def latlon_to_country_code_batch(coords):\n",
    "    \"\"\"\n",
    "    Batch process reverse geocoding.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = rg.search(coords)  # Batch process\n",
    "        return [res['cc'] for res in results]\n",
    "    except Exception as e:\n",
    "        print(f\"Batch reverse geocode failed. Error: {e}\")\n",
    "        return [None] * len(coords)\n",
    "\n",
    "def alpha2_to_country_name(alpha2):\n",
    "    \"\"\"\n",
    "    Converts ISO alpha-2 code to the official country name.\n",
    "    \"\"\"\n",
    "    country = pycountry.countries.get(alpha_2=alpha2)\n",
    "    return country.name if country else None\n",
    "\n",
    "def alpha2_to_continent(alpha2):\n",
    "    \"\"\"\n",
    "    Converts an ISO alpha-2 code to the name of the continent.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        continent_code = pc.country_alpha2_to_continent_code(alpha2)\n",
    "        continent_map = {\n",
    "            \"AF\": \"Africa\",\n",
    "            \"NA\": \"North America\",\n",
    "            \"SA\": \"South America\",\n",
    "            \"OC\": \"Oceania\",\n",
    "            \"AS\": \"Asia\",\n",
    "            \"EU\": \"Europe\",\n",
    "            \"AN\": \"Antarctica\"\n",
    "        }\n",
    "        return continent_map.get(continent_code, None)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# ---------------------------\n",
    "# 2. Process entire dataset with parallel processing\n",
    "# ---------------------------\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Processes a chunk of the DataFrame, performing reverse geocoding\n",
    "    and mapping country/continent information.\n",
    "    \"\"\"\n",
    "    coords = list(zip(chunk[\"latitude\"], chunk[\"longitude\"]))\n",
    "    # Perform batch reverse geocoding\n",
    "    country_codes = latlon_to_country_code_batch(coords)\n",
    "    chunk[\"country_code\"] = country_codes\n",
    "    # Convert country codes to country names\n",
    "    chunk[\"country\"] = [alpha2_to_country_name(cc) for cc in country_codes]\n",
    "    # Convert country codes to continents\n",
    "    chunk[\"continent\"] = [alpha2_to_continent(cc) for cc in country_codes]\n",
    "    chunk[\"region\"] = chunk[\"country\"]\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n"
     ]
    }
   ],
   "source": [
    "num_threads = 4\n",
    "chunk_size = max(1, len(df) // num_threads)  # Ensure chunk_size is at least 1\n",
    "chunks = [df.iloc[i:i + chunk_size].copy() for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Process chunks in parallel\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    results = list(executor.map(process_chunk, chunks))\n",
    "    \n",
    "df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "all_df = pd.read_csv('all.csv')\n",
    "\n",
    "df = df.merge(all_df[['alpha-2', 'sub-region']], left_on='country_code', right_on='alpha-2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>alpha-2</th>\n",
       "      <th>sub-region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.824885</td>\n",
       "      <td>-98.499517</td>\n",
       "      <td>0.png</td>\n",
       "      <td>MX</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>North America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>MX</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.451752</td>\n",
       "      <td>-54.563937</td>\n",
       "      <td>1.png</td>\n",
       "      <td>BR</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23.496464</td>\n",
       "      <td>-47.460542</td>\n",
       "      <td>2.png</td>\n",
       "      <td>BR</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.548678</td>\n",
       "      <td>-72.852778</td>\n",
       "      <td>3.png</td>\n",
       "      <td>PE</td>\n",
       "      <td>Peru</td>\n",
       "      <td>South America</td>\n",
       "      <td>Peru</td>\n",
       "      <td>PE</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35.010870</td>\n",
       "      <td>140.064397</td>\n",
       "      <td>4.png</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia and New Zealand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude image_name country_code    country      continent  \\\n",
       "0  20.824885  -98.499517      0.png           MX     Mexico  North America   \n",
       "1  -3.451752  -54.563937      1.png           BR     Brazil  South America   \n",
       "2 -23.496464  -47.460542      2.png           BR     Brazil  South America   \n",
       "3 -16.548678  -72.852778      3.png           PE       Peru  South America   \n",
       "4 -35.010870  140.064397      4.png           AU  Australia        Oceania   \n",
       "\n",
       "      region alpha-2                       sub-region  \n",
       "0     Mexico      MX  Latin America and the Caribbean  \n",
       "1     Brazil      BR  Latin America and the Caribbean  \n",
       "2     Brazil      BR  Latin America and the Caribbean  \n",
       "3       Peru      PE  Latin America and the Caribbean  \n",
       "4  Australia      AU        Australia and New Zealand  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub-region\n",
       "Melanesia                             3\n",
       "Central Asia                         41\n",
       "Northern Africa                      44\n",
       "Southern Asia                       886\n",
       "Western Asia                       1004\n",
       "Eastern Asia                       1290\n",
       "South-eastern Asia                 1406\n",
       "Australia and New Zealand          1658\n",
       "Southern Europe                    1678\n",
       "Sub-Saharan Africa                 1946\n",
       "Western Europe                     2026\n",
       "Northern Europe                    2181\n",
       "Eastern Europe                     2949\n",
       "Northern America                   3141\n",
       "Latin America and the Caribbean    4955\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_counts = df.groupby('sub-region').size().sort_values()\n",
    "region_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_regions = region_counts[region_counts < 500].index\n",
    "df = df[~df['sub-region'].isin(drop_regions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(image, image_name, image_path=OUTPUT_PATH):\n",
    "    \"\"\"Writes the image to disk.\"\"\"\n",
    "    io.write_png(image, image_path + image_name)\n",
    "\n",
    "def augment_data(image_name, input_image_path=DATA_PATH):\n",
    "    \"\"\"Applies augmentation transformations to an image.\"\"\"\n",
    "    image = io.read_image(input_image_path + image_name)\n",
    "    \n",
    "    transform = v2.Compose([\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.RandomRotation(degrees=15),\n",
    "        v2.ColorJitter(brightness=(0.85, 1.15)),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "def batch_augment_data(image_names, input_image_path=DATA_PATH):\n",
    "    \"\"\"Augments a batch of images.\"\"\"\n",
    "    return [augment_data(image_name, input_image_path) for image_name in image_names]\n",
    "\n",
    "def balance_classes(df):\n",
    "    \"\"\"Balances the classes by augmenting underrepresented samples.\"\"\"\n",
    "    class_counts = df['sub-region'].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "    skip_classes = ['Latin America and the Caribbean', 'Northern America', 'Eastern Europe', 'Northern Europe', 'Western Europe', 'Sub-Saharan Africa', 'Australia and New Zealand', 'Southern Europe', 'South-eastern Asia', 'Eastern Asia']\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "    else:\n",
    "        # Clear the directory\n",
    "        [os.remove(OUTPUT_PATH + filename) for filename in os.listdir(OUTPUT_PATH)]\n",
    "\n",
    "    for cls, count in class_counts.items():\n",
    "        if cls in skip_classes:\n",
    "            continue\n",
    "        print(f\"Handling class {cls}\")\n",
    "        num_samples_needed = max_count - count\n",
    "        class_df = df[df['sub-region'] == cls]\n",
    "\n",
    "        if num_samples_needed > 0:  # Augment minority class\n",
    "            print(f\"Augmenting {num_samples_needed} images for class {cls}\")\n",
    "            resampled_df = class_df.sample(n=num_samples_needed, replace=True)\n",
    "            augmented_images = batch_augment_data(resampled_df['image_name'].tolist())\n",
    "            resampled_df['image_name'] = 'augmented_'+ uuid.uuid4().hex[:8] + resampled_df['image_name']\n",
    "            \n",
    "            # Create new rows\n",
    "            for i, (image_name, augmented_image) in enumerate(zip(resampled_df['image_name'], augmented_images)):\n",
    "                write_image(augmented_image, image_name)\n",
    "            df = pd.concat([df, resampled_df], ignore_index=True)\n",
    "        else:  # Augment majority class for diversity\n",
    "            sample_size = len(class_df) // 4\n",
    "            print(f\"Augmenting {sample_size} images for class {cls}\")\n",
    "            sampled_df = class_df.sample(n=sample_size)\n",
    "            augmented_images = batch_augment_data(sampled_df['image_name'].tolist())\n",
    "            sampled_df['image_name'] = 'augmented_' + uuid.uuid4().hex[:8] + sampled_df['image_name']\n",
    "            df.loc[sampled_df.index] = sampled_df\n",
    "            # Update rows\n",
    "            for i, (image_name, augmented_image) in enumerate(zip(sampled_df['image_name'], augmented_images)):\n",
    "                write_image(augmented_image, image_name)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling class Western Asia\n",
      "Augmenting 3162 images for class Western Asia\n"
     ]
    }
   ],
   "source": [
    "df_train['is_augmented'] = False\n",
    "df_train['aumentation_source_image_name'] = df_train['image_name']\n",
    "df_train = balance_classes(df_train)\n",
    "for image_name in df_train[~df_train['is_augmented']]['image_name']:\n",
    "    image = io.read_image(DATA_PATH + image_name)\n",
    "    write_image(image, OUTPUT_PATH + image_name)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(OUTPUT_PATH + 'train.csv', index=False)\n",
    "df_test.to_csv(OUTPUT_PATH + 'test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
