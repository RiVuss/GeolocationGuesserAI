{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import reverse_geocoder as rg\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "from torchvision import io\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = 'Streetview_Image_Dataset/'\n",
    "DATA_PATH = SOURCE \n",
    "\n",
    "CSV_NAME = 'coordinates.csv'\n",
    "OUTPUT_PATH = SOURCE + 'processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.824885</td>\n",
       "      <td>-98.499517</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.451752</td>\n",
       "      <td>-54.563937</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23.496464</td>\n",
       "      <td>-47.460542</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.548678</td>\n",
       "      <td>-72.852778</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35.010870</td>\n",
       "      <td>140.064397</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude image_name\n",
       "0  20.824885  -98.499517      0.png\n",
       "1  -3.451752  -54.563937      1.png\n",
       "2 -23.496464  -47.460542      2.png\n",
       "3 -16.548678  -72.852778      3.png\n",
       "4 -35.010870  140.064397      4.png"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column_names = [\"latitude\", \"longitude\"]\n",
    "df = pd.read_csv(DATA_PATH + CSV_NAME,)\n",
    "df['image_name'] = df.index.astype('str') + '.png'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Helper functions for offline country/continent lookups\n",
    "# ---------------------------\n",
    "def latlon_to_country_code_batch(coords):\n",
    "    \"\"\"\n",
    "    Batch process reverse geocoding.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = rg.search(coords)  # Batch process\n",
    "        return [res['cc'] for res in results]\n",
    "    except Exception as e:\n",
    "        print(f\"Batch reverse geocode failed. Error: {e}\")\n",
    "        return [None] * len(coords)\n",
    "\n",
    "def alpha2_to_country_name(alpha2):\n",
    "    \"\"\"\n",
    "    Converts ISO alpha-2 code to the official country name.\n",
    "    \"\"\"\n",
    "    country = pycountry.countries.get(alpha_2=alpha2)\n",
    "    return country.name if country else None\n",
    "\n",
    "def alpha2_to_continent(alpha2):\n",
    "    \"\"\"\n",
    "    Converts an ISO alpha-2 code to the name of the continent.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        continent_code = pc.country_alpha2_to_continent_code(alpha2)\n",
    "        continent_map = {\n",
    "            \"AF\": \"Africa\",\n",
    "            \"NA\": \"North America\",\n",
    "            \"SA\": \"South America\",\n",
    "            \"OC\": \"Oceania\",\n",
    "            \"AS\": \"Asia\",\n",
    "            \"EU\": \"Europe\",\n",
    "            \"AN\": \"Antarctica\"\n",
    "        }\n",
    "        return continent_map.get(continent_code, None)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# ---------------------------\n",
    "# 2. Process entire dataset with parallel processing\n",
    "# ---------------------------\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Processes a chunk of the DataFrame, performing reverse geocoding\n",
    "    and mapping country/continent information.\n",
    "    \"\"\"\n",
    "    coords = list(zip(chunk[\"latitude\"], chunk[\"longitude\"]))\n",
    "    # Perform batch reverse geocoding\n",
    "    country_codes = latlon_to_country_code_batch(coords)\n",
    "    chunk[\"country_code\"] = country_codes\n",
    "    # Convert country codes to country names\n",
    "    chunk[\"country\"] = [alpha2_to_country_name(cc) for cc in country_codes]\n",
    "    # Convert country codes to continents\n",
    "    chunk[\"continent\"] = [alpha2_to_continent(cc) for cc in country_codes]\n",
    "    chunk[\"region\"] = chunk[\"country\"]\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n"
     ]
    }
   ],
   "source": [
    "num_threads = 4\n",
    "chunk_size = max(1, len(df) // num_threads)  # Ensure chunk_size is at least 1\n",
    "chunks = [df.iloc[i:i + chunk_size].copy() for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Process chunks in parallel\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    results = list(executor.map(process_chunk, chunks))\n",
    "    \n",
    "df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "all_df = pd.read_csv('all.csv')\n",
    "\n",
    "df = df.merge(all_df[['alpha-2', 'sub-region']], left_on='country_code', right_on='alpha-2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>alpha-2</th>\n",
       "      <th>sub-region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.824885</td>\n",
       "      <td>-98.499517</td>\n",
       "      <td>0.png</td>\n",
       "      <td>MX</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>North America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>MX</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.451752</td>\n",
       "      <td>-54.563937</td>\n",
       "      <td>1.png</td>\n",
       "      <td>BR</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23.496464</td>\n",
       "      <td>-47.460542</td>\n",
       "      <td>2.png</td>\n",
       "      <td>BR</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.548678</td>\n",
       "      <td>-72.852778</td>\n",
       "      <td>3.png</td>\n",
       "      <td>PE</td>\n",
       "      <td>Peru</td>\n",
       "      <td>South America</td>\n",
       "      <td>Peru</td>\n",
       "      <td>PE</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35.010870</td>\n",
       "      <td>140.064397</td>\n",
       "      <td>4.png</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia and New Zealand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude image_name country_code    country      continent  \\\n",
       "0  20.824885  -98.499517      0.png           MX     Mexico  North America   \n",
       "1  -3.451752  -54.563937      1.png           BR     Brazil  South America   \n",
       "2 -23.496464  -47.460542      2.png           BR     Brazil  South America   \n",
       "3 -16.548678  -72.852778      3.png           PE       Peru  South America   \n",
       "4 -35.010870  140.064397      4.png           AU  Australia        Oceania   \n",
       "\n",
       "      region alpha-2                       sub-region  \n",
       "0     Mexico      MX  Latin America and the Caribbean  \n",
       "1     Brazil      BR  Latin America and the Caribbean  \n",
       "2     Brazil      BR  Latin America and the Caribbean  \n",
       "3       Peru      PE  Latin America and the Caribbean  \n",
       "4  Australia      AU        Australia and New Zealand  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub-region\n",
       "Melanesia                             3\n",
       "Central Asia                         41\n",
       "Northern Africa                      44\n",
       "Southern Asia                       886\n",
       "Western Asia                       1004\n",
       "Eastern Asia                       1290\n",
       "South-eastern Asia                 1406\n",
       "Australia and New Zealand          1658\n",
       "Southern Europe                    1678\n",
       "Sub-Saharan Africa                 1946\n",
       "Western Europe                     2026\n",
       "Northern Europe                    2181\n",
       "Eastern Europe                     2949\n",
       "Northern America                   3141\n",
       "Latin America and the Caribbean    4955\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_counts = df.groupby('sub-region').size().sort_values()\n",
    "region_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_regions = region_counts[region_counts < 500].index\n",
    "df = df[~df['sub-region'].isin(drop_regions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torchvision import io, transforms as T\n",
    "\n",
    "# If you have not defined these paths already, you need to define them.\n",
    "# For example:\n",
    "OUTPUT_PATH = \"augmented_output/\"\n",
    "DATA_PATH = \"Streetview_Image_Dataset/raw/\"\n",
    "\n",
    "# Detect if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def write_image(image_tensor, image_name, image_path=OUTPUT_PATH):\n",
    "    \"\"\"\n",
    "    Writes a PyTorch tensor image to disk as PNG.\n",
    "    Assumes `image_tensor` is in [C, H, W] format on the CPU.\n",
    "    \"\"\"\n",
    "    # Make sure the output directory exists.\n",
    "    if not os.path.exists(image_path):\n",
    "        os.makedirs(image_path, exist_ok=True)\n",
    "\n",
    "    # Use torchvision.io.write_png to save the tensor as a PNG file.\n",
    "    io.write_png(image_tensor, os.path.join(image_path, image_name))\n",
    "\n",
    "\n",
    "def augment_data(image_name, input_image_path=DATA_PATH, device=device):\n",
    "    # 1. Read the image as a torch tensor [C, H, W] in [0, 255] (uint8).\n",
    "    image_path = os.path.join(input_image_path, image_name)\n",
    "    image = io.read_image(image_path)  # shape: [C, H, W], dtype=uint8, range=[0,255]\n",
    "\n",
    "    # 2. Convert to float in [0,1] and move to GPU (if available).\n",
    "    image = image.float() / 255.0  # now in range [0,1]\n",
    "    image = image.to(device=device)\n",
    "\n",
    "    # 3. Define your transformations (which assume [0,1] floating points).\n",
    "    transform = T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=15),\n",
    "        T.ColorJitter(brightness=(0.85, 1.15)),\n",
    "    ])\n",
    "\n",
    "    # 4. Apply transformations.\n",
    "    augmented_image = transform(image)\n",
    "\n",
    "    # 5. Scale back to [0,255], convert to uint8, move back to CPU.\n",
    "    augmented_image = (augmented_image * 255.0).clamp(0, 255).to(torch.uint8).cpu()\n",
    "\n",
    "    return augmented_image\n",
    "\n",
    "\n",
    "def batch_augment_data(image_names, input_image_path=DATA_PATH, device=device):\n",
    "    \"\"\"\n",
    "    Augments a batch of images, returning a list of augmented tensors.\n",
    "    Includes a progress bar for the batch process.\n",
    "    \"\"\"\n",
    "    augmented_images = []\n",
    "    for name in tqdm(image_names, desc=\"Batch Augmenting\"):\n",
    "        augmented_images.append(augment_data(name, input_image_path, device=device))\n",
    "    return augmented_images\n",
    "\n",
    "\n",
    "def balance_classes(df):\n",
    "    \"\"\"\n",
    "    Balances the classes by augmenting underrepresented samples (minority classes)\n",
    "    or augmenting some subset of overrepresented classes (majority classes) for diversity.\n",
    "    Includes a progress bar for class balancing.\n",
    "    \"\"\"\n",
    "    class_counts = df['sub-region'].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "\n",
    "    skip_classes = [\n",
    "        'Western Asia', 'Southern Asia',  'Northern Europe','Eastern Europe','Northern America','Latin America and the Caribbean'\n",
    "    ]\n",
    "\n",
    "   \n",
    "\n",
    "    # Show progress over the classes\n",
    "    for cls, count in tqdm(class_counts.items(), desc=\"Balancing Classes\"):\n",
    "        if cls in skip_classes:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nHandling class: {cls} (current count: {count})\")\n",
    "        num_samples_needed = max_count - count\n",
    "        class_df = df[df['sub-region'] == cls]\n",
    "\n",
    "        if num_samples_needed > 0:\n",
    "            # Augment minority class (underrepresented)\n",
    "            print(f\" -> Augmenting {num_samples_needed} images for class '{cls}'\")\n",
    "            resampled_df = class_df.sample(n=num_samples_needed, replace=True)\n",
    "\n",
    "            # Perform the actual augmentations\n",
    "            augmented_images = batch_augment_data(resampled_df['image_name'].tolist())\n",
    "\n",
    "            # Give new names to the augmented images\n",
    "            # Example: \"augmented_af12b345original.png\"\n",
    "            new_names = [\n",
    "                f\"augmented_{uuid.uuid4().hex[:8]}_{img_name}\"\n",
    "                for img_name in resampled_df['image_name']\n",
    "            ]\n",
    "            resampled_df['image_name'] = new_names\n",
    "\n",
    "            # Write the images to disk and add rows to df\n",
    "            for (image_name, augmented_image) in zip(resampled_df['image_name'], augmented_images):\n",
    "                write_image(augmented_image, image_name)\n",
    "\n",
    "            # Concatenate the newly augmented rows to the original dataframe\n",
    "            df = pd.concat([df, resampled_df], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            # Augment some samples from the majority class for diversity\n",
    "            # For example, take 25% of them to re-augment\n",
    "            sample_size = len(class_df) // 4\n",
    "            print(f\" -> Augmenting {sample_size} images for class '{cls}'\")\n",
    "            sampled_df = class_df.sample(n=sample_size)\n",
    "\n",
    "            # Perform the actual augmentations\n",
    "            augmented_images = batch_augment_data(sampled_df['image_name'].tolist())\n",
    "\n",
    "            # Generate new names (or you can overwrite if you prefer)\n",
    "            new_names = [\n",
    "                f\"augmented_{uuid.uuid4().hex[:8]}_{img_name}\"\n",
    "                for img_name in sampled_df['image_name']\n",
    "            ]\n",
    "            sampled_df['image_name'] = new_names\n",
    "\n",
    "            # Write the images to disk and update the existing rows in df\n",
    "            for index, augmented_image in zip(sampled_df.index, augmented_images):\n",
    "                write_image(augmented_image, sampled_df.loc[index, 'image_name'])\n",
    "            \n",
    "            # Update the dataframe in-place with the new image names\n",
    "            df.loc[sampled_df.index] = sampled_df\n",
    "\n",
    "    print(\"\\nBalancing done!\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Classes: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling class: Western Europe (current count: 1604)\n",
      " -> Augmenting 2368 images for class 'Western Europe'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Augmenting: 100%|██████████| 2368/2368 [00:19<00:00, 123.15it/s]\n",
      "Balancing Classes: 7it [04:18, 36.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling class: Sub-Saharan Africa (current count: 1539)\n",
      " -> Augmenting 2433 images for class 'Sub-Saharan Africa'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Augmenting: 100%|██████████| 2433/2433 [00:16<00:00, 145.13it/s]\n",
      "Balancing Classes: 8it [08:19, 71.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling class: Australia and New Zealand (current count: 1330)\n",
      " -> Augmenting 2642 images for class 'Australia and New Zealand'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Augmenting: 100%|██████████| 2642/2642 [00:20<00:00, 130.40it/s]\n",
      "Balancing Classes: 9it [13:25, 117.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling class: Southern Europe (current count: 1328)\n",
      " -> Augmenting 2644 images for class 'Southern Europe'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Augmenting: 100%|██████████| 2644/2644 [00:22<00:00, 118.43it/s]\n",
      "Balancing Classes: 10it [17:57, 150.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling class: South-eastern Asia (current count: 1162)\n",
      " -> Augmenting 2810 images for class 'South-eastern Asia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Augmenting: 100%|██████████| 2810/2810 [00:22<00:00, 124.15it/s]\n",
      "Balancing Classes: 11it [22:33, 180.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling class: Eastern Asia (current count: 1056)\n",
      " -> Augmenting 2916 images for class 'Eastern Asia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Augmenting: 100%|██████████| 2916/2916 [00:23<00:00, 123.99it/s]\n",
      "Balancing Classes: 12it [27:42, 138.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balancing done!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error opening output file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m df_train[\u001b[38;5;241m~\u001b[39mdf_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_augmented\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mread_image(DATA_PATH \u001b[38;5;241m+\u001b[39m image_name)\n\u001b[1;32m----> 6\u001b[0m     write_image(image, OUTPUT_PATH \u001b[38;5;241m+\u001b[39m image_name)\n\u001b[0;32m      7\u001b[0m df_train\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[27], line 29\u001b[0m, in \u001b[0;36mwrite_image\u001b[1;34m(image_tensor, image_name, image_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(image_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Use torchvision.io.write_png to save the tensor as a PNG file.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m io\u001b[38;5;241m.\u001b[39mwrite_png(image_tensor, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_path, image_name))\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:153\u001b[0m, in \u001b[0;36mwrite_png\u001b[1;34m(input, filename, compression_level)\u001b[0m\n\u001b[0;32m    151\u001b[0m     _log_api_usage_once(write_png)\n\u001b[0;32m    152\u001b[0m output \u001b[38;5;241m=\u001b[39m encode_png(\u001b[38;5;28minput\u001b[39m, compression_level)\n\u001b[1;32m--> 153\u001b[0m write_file(filename, output)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:78\u001b[0m, in \u001b[0;36mwrite_file\u001b[1;34m(filename, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m     77\u001b[0m     _log_api_usage_once(write_file)\n\u001b[1;32m---> 78\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mwrite_file(\u001b[38;5;28mstr\u001b[39m(filename), data)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening output file"
     ]
    }
   ],
   "source": [
    "df_train['is_augmented'] = False\n",
    "df_train['aumentation_source_image_name'] = df_train['image_name']\n",
    "df_train = balance_classes(df_train)\n",
    "for image_name in df_train[~df_train['is_augmented']]['image_name']:\n",
    "    image = io.read_image(DATA_PATH + image_name)\n",
    "    write_image(image, OUTPUT_PATH + image_name)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>alpha-2</th>\n",
       "      <th>sub-region</th>\n",
       "      <th>is_augmented</th>\n",
       "      <th>aumentation_source_image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.603220</td>\n",
       "      <td>15.538784</td>\n",
       "      <td>3388.png</td>\n",
       "      <td>HR</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>HR</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>False</td>\n",
       "      <td>3388.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.382881</td>\n",
       "      <td>3.673380</td>\n",
       "      <td>2963.png</td>\n",
       "      <td>NG</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NG</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>False</td>\n",
       "      <td>2963.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.400360</td>\n",
       "      <td>103.894100</td>\n",
       "      <td>14138.png</td>\n",
       "      <td>MY</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>MY</td>\n",
       "      <td>South-eastern Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>14138.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.949390</td>\n",
       "      <td>-7.846810</td>\n",
       "      <td>23442.png</td>\n",
       "      <td>IE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>IE</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>False</td>\n",
       "      <td>23442.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.186400</td>\n",
       "      <td>34.864500</td>\n",
       "      <td>20450.png</td>\n",
       "      <td>IL</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Israel</td>\n",
       "      <td>IL</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>20450.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26558</th>\n",
       "      <td>24.664557</td>\n",
       "      <td>90.457702</td>\n",
       "      <td>augmented_f90d1b8c_6236.png</td>\n",
       "      <td>BD</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>6236.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26559</th>\n",
       "      <td>6.904470</td>\n",
       "      <td>79.897070</td>\n",
       "      <td>augmented_eddb7422_23318.png</td>\n",
       "      <td>LK</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>LK</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>23318.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26560</th>\n",
       "      <td>23.528160</td>\n",
       "      <td>89.142910</td>\n",
       "      <td>augmented_f8809b08_11914.png</td>\n",
       "      <td>BD</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>11914.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26561</th>\n",
       "      <td>24.726360</td>\n",
       "      <td>74.052621</td>\n",
       "      <td>augmented_c746e873_3163.png</td>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>3163.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26562</th>\n",
       "      <td>24.630214</td>\n",
       "      <td>73.893928</td>\n",
       "      <td>augmented_9a47406f_6851.png</td>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>6851.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26563 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude   longitude                    image_name country_code  \\\n",
       "0      45.603220   15.538784                      3388.png           HR   \n",
       "1       7.382881    3.673380                      2963.png           NG   \n",
       "2       1.400360  103.894100                     14138.png           MY   \n",
       "3      53.949390   -7.846810                     23442.png           IE   \n",
       "4      32.186400   34.864500                     20450.png           IL   \n",
       "...          ...         ...                           ...          ...   \n",
       "26558  24.664557   90.457702   augmented_f90d1b8c_6236.png           BD   \n",
       "26559   6.904470   79.897070  augmented_eddb7422_23318.png           LK   \n",
       "26560  23.528160   89.142910  augmented_f8809b08_11914.png           BD   \n",
       "26561  24.726360   74.052621   augmented_c746e873_3163.png           IN   \n",
       "26562  24.630214   73.893928   augmented_9a47406f_6851.png           IN   \n",
       "\n",
       "          country continent      region alpha-2          sub-region  \\\n",
       "0         Croatia    Europe     Croatia      HR     Southern Europe   \n",
       "1         Nigeria    Africa     Nigeria      NG  Sub-Saharan Africa   \n",
       "2        Malaysia      Asia    Malaysia      MY  South-eastern Asia   \n",
       "3         Ireland    Europe     Ireland      IE     Northern Europe   \n",
       "4          Israel      Asia      Israel      IL        Western Asia   \n",
       "...           ...       ...         ...     ...                 ...   \n",
       "26558  Bangladesh      Asia  Bangladesh      BD       Southern Asia   \n",
       "26559   Sri Lanka      Asia   Sri Lanka      LK       Southern Asia   \n",
       "26560  Bangladesh      Asia  Bangladesh      BD       Southern Asia   \n",
       "26561       India      Asia       India      IN       Southern Asia   \n",
       "26562       India      Asia       India      IN       Southern Asia   \n",
       "\n",
       "       is_augmented aumentation_source_image_name  \n",
       "0             False                      3388.png  \n",
       "1             False                      2963.png  \n",
       "2             False                     14138.png  \n",
       "3             False                     23442.png  \n",
       "4             False                     20450.png  \n",
       "...             ...                           ...  \n",
       "26558         False                      6236.png  \n",
       "26559         False                     23318.png  \n",
       "26560         False                     11914.png  \n",
       "26561         False                      3163.png  \n",
       "26562         False                      6851.png  \n",
       "\n",
       "[26563 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv', index=False)\n",
    "df_test.to_csv('test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
