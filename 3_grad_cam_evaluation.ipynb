{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import io\n",
    "from torchvision.models import resnet18, ResNet18_Weights, resnet50, resnet101, ResNet101_Weights, ResNet50_Weights\n",
    "from tqdm import tqdm  # For progress bars\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet18\n",
    "import cv2  # For resizing and processing the Grad-CAMÂ heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_29000\\1523254426.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Grad-CAM for 0.png to grad-cam\\gradcam_0.jpeg\n",
      "Saved masked ROI for 0.png to grad-cam\\rois\\roi_0_0.jpeg\n",
      "Saved Grad-CAM for 1.png to grad-cam\\gradcam_1.jpeg\n",
      "Saved masked ROI for 1.png to grad-cam\\rois\\roi_1_0.jpeg\n",
      "Saved Grad-CAM for 2.png to grad-cam\\gradcam_2.jpeg\n",
      "Saved masked ROI for 2.png to grad-cam\\rois\\roi_2_0.jpeg\n",
      "Saved masked ROI for 2.png to grad-cam\\rois\\roi_2_1.jpeg\n",
      "Saved masked ROI for 2.png to grad-cam\\rois\\roi_2_2.jpeg\n",
      "Grad-CAM visualizations and ROIs saved in grad-cam.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# User-specified range of images to process\n",
    "start_index = 0  # Change as per user input\n",
    "end_index = 3   # Change as per user input 25229\n",
    "image_range = range(start_index, end_index)\n",
    "\n",
    "# Paths\n",
    "model_path = \"models/resnet18/model.pth\"\n",
    "dataset_path = \"Streetview_Image_Dataset\"\n",
    "output_dir = \"grad-cam\"\n",
    "\n",
    "# Load pre-trained ResNet model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=False)\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "# Temporarily set the fc layer to match the checkpoint dimensions\n",
    "model.fc = torch.nn.Linear(num_features, 17)  # Match the checkpoint's number of output classes\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Replace the fc layer for the current task (4 classes)\n",
    "model.fc = torch.nn.Linear(num_features, 4)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Select images based on the specified range\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
    "sorted_image_files = sorted(image_files, key=lambda x: int(os.path.splitext(x)[0]))  # Sort by numeric order\n",
    "selected_images = [f\"{i}.png\" for i in image_range if f\"{i}.png\" in sorted_image_files]\n",
    "\n",
    "# Grad-CAM setup\n",
    "target_layers = [model.layer4[-1]]  # Last convolutional layer\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each image and generate Grad-CAM visualizations\n",
    "for idx, image_file in enumerate(selected_images):\n",
    "    image_path = os.path.join(dataset_path, image_file)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)  # Prepare input tensor\n",
    "\n",
    "    # Specify target class (optional; defaults to predicted class if None)\n",
    "    targets = None  # Alternatively, specify class index with ClassifierOutputTarget(class_index)\n",
    "\n",
    "    # Construct Grad-CAM object and generate heatmap\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]  # Extract heatmap for the first image in the batch\n",
    "\n",
    "        # Resize Grad-CAM heatmap to match the original image dimensions\n",
    "        grayscale_cam_resized = cv2.resize(grayscale_cam, (image.width, image.height))\n",
    "\n",
    "        # Threshold the heatmap to isolate the ROI\n",
    "        threshold_value = 0.5  # Adjust threshold as needed\n",
    "        _, binary_heatmap = cv2.threshold(grayscale_cam_resized, threshold_value, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Convert binary heatmap to uint8 for contour detection\n",
    "        binary_heatmap_uint8 = (binary_heatmap * 255).astype(np.uint8)\n",
    "\n",
    "        # Find contours in the thresholded heatmap\n",
    "        contours, _ = cv2.findContours(binary_heatmap_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw contours and extract bounding boxes for each detected ROI\n",
    "        rois = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)  # Bounding box around the ROI\n",
    "            rois.append((x, y, w, h))  # Store ROI coordinates\n",
    "\n",
    "        # Overlay heatmap on the original image\n",
    "        image_np = np.array(image) / 255.0  # Normalize image to range [0, 1]\n",
    "        visualization = show_cam_on_image(image_np, grayscale_cam_resized, use_rgb=True)\n",
    "\n",
    "        # Save the Grad-CAM visualization\n",
    "        output_path = os.path.join(output_dir, f\"gradcam_{os.path.splitext(image_file)[0]}.jpeg\")\n",
    "        Image.fromarray(visualization).save(output_path)\n",
    "        print(f\"Saved Grad-CAM for {image_file} to {output_path}\")\n",
    "\n",
    "        # Save each ROI as a cropped image with non-red parts masked as black\n",
    "        roi_dir = os.path.join(output_dir, \"rois\")\n",
    "        os.makedirs(roi_dir, exist_ok=True)\n",
    "        for roi_idx, (x, y, w, h) in enumerate(rois):\n",
    "            # Crop the original image to the ROI\n",
    "            roi_image = image.crop((x, y, x + w, y + h))\n",
    "            roi_np = np.array(roi_image)  # Convert to numpy array\n",
    "\n",
    "            # Crop the heatmap to match the ROI dimensions\n",
    "            heatmap_roi = grayscale_cam_resized[y:y + h, x:x + w]\n",
    "            heatmap_binary = (heatmap_roi >= threshold_value).astype(np.uint8)\n",
    "\n",
    "            # Create a mask with the binary heatmap\n",
    "            mask = np.repeat(heatmap_binary[:, :, np.newaxis], 3, axis=2)  # Repeat for 3 channels (RGB)\n",
    "\n",
    "            # Apply the mask to the ROI (black out non-red regions)\n",
    "            masked_roi = roi_np * mask\n",
    "\n",
    "            # Convert the masked ROI back to an image\n",
    "            masked_roi_image = Image.fromarray(masked_roi.astype(np.uint8))\n",
    "\n",
    "            # Save the masked ROI image\n",
    "            roi_output_path = os.path.join(roi_dir, f\"roi_{os.path.splitext(image_file)[0]}_{roi_idx}.jpeg\")\n",
    "            masked_roi_image.save(roi_output_path)\n",
    "            print(f\"Saved masked ROI for {image_file} to {roi_output_path}\")\n",
    "\n",
    "print(f\"Grad-CAM visualizations and ROIs saved in {output_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 656 files in the directory 'grad-cam/rois'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory path\n",
    "directory_path = \"grad-cam/rois\"\n",
    "\n",
    "# Count the number of files in the directory\n",
    "file_count = len([f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))])\n",
    "\n",
    "print(f\"There are {file_count} files in the directory '{directory_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
