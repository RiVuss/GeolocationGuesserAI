{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resnet 18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import io\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read and transform images\n",
    "def read_image(image_path):\n",
    "    img = io.read_image(image_path)\n",
    "    weights = ResNet18_Weights.DEFAULT\n",
    "    transform = weights.transforms()\n",
    "    return transform(img)\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "\n",
    "    train_accuracy = correct / len(train_loader.dataset)\n",
    "    train_loss /= len(train_loader)\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "# Testing function\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.continent_mapping = {continent: idx for idx, continent in enumerate(self.data['continent'].unique())}\n",
    "        self.data['continent_label'] = self.data['continent'].map(self.continent_mapping)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.data.iloc[idx]['image_name'])\n",
    "        image = io.read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.data.iloc[idx]['continent_label']\n",
    "        return image, label\n",
    "\n",
    "# Main training loop\n",
    "def train_loop(csv_path, root_dir, num_epochs=15, batch_size=32, learning_rate=0.001, weight_decay=0.0001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Data transformations\n",
    "    weights = ResNet18_Weights.DEFAULT\n",
    "    transform = weights.transforms()\n",
    "\n",
    "    # Dataset and DataLoaders\n",
    "    dataset = CustomDataset(csv_file=csv_path, root_dir=root_dir, transform=transform)\n",
    "    train_idx, test_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "    train_set = torch.utils.data.Subset(dataset, train_idx)\n",
    "    test_set = torch.utils.data.Subset(dataset, test_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Load ResNet18 and modify the final layer\n",
    "    resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False  # Freeze all layers except the last\n",
    "    num_features = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(num_features, 6)  # 6 continents\n",
    "    resnet.to(device)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(resnet.fc.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Training and evaluation\n",
    "    metrics = pd.DataFrame(columns=['epoch', 'train_loss', 'train_accuracy', 'test_loss', 'test_accuracy'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(resnet, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_accuracy = test(resnet, test_loader, criterion, device)\n",
    "\n",
    "        # Save metrics and model\n",
    "        metrics = metrics.append({'epoch': epoch, 'train_loss': train_loss, 'train_accuracy': train_accuracy,\n",
    "                                  'test_loss': test_loss, 'test_accuracy': test_accuracy}, ignore_index=True)\n",
    "        metrics.to_csv('metrics.csv', index=False)\n",
    "        torch.save(resnet.state_dict(), 'model.pth')\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}: \"\n",
    "              f\"Train Loss={train_loss:.4f}, Train Acc={train_accuracy:.4f}, \"\n",
    "              f\"Test Loss={test_loss:.4f}, Test Acc={test_accuracy:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "# Example usage\n",
    "# Ensure 'coords_processed.csv' and 'dataset/' are properly set up\n",
    "train_loop(csv_path='coords_processed.csv', root_dir='dataset/', num_epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-win_amd64.whl (2510.8 MB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-win_amd64.whl (6.1 MB)\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.6/6.1 MB 18.5 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 1.1/6.1 MB 14.2 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.6/6.1 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.2/6.1 MB 12.7 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 2.7/6.1 MB 12.4 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.3/6.1 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 3.9/6.1 MB 12.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 4.4/6.1 MB 12.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 4.9/6.1 MB 12.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.5/6.1 MB 12.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.0/6.1 MB 12.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.1/6.1 MB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user1\\anaconda3\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user1\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user1\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user1\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-2.5.1+cu124 torchvision-0.20.1+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  9 16:46:00 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   50C    P0             25W /  280W |    1230MiB /   8192MiB |     42%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2260    C+G   ...al\\Discord\\app-1.0.9175\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A      2876    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A      3096    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      4640    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A      5420    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      6492    C+G   ...6.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     13516    C+G   ...n\\131.0.2903.112\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     14652    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14676    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16852    C+G   ...-desktop\\RemoteDesktopCompanion.exe      N/A      |\n",
      "|    0   N/A  N/A     18700    C+G   ...n\\131.0.2903.112\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     19108    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     20432    C+G   ...grams\\twinkle-tray\\Twinkle Tray.exe      N/A      |\n",
      "|    0   N/A  N/A     20448    C+G   ...64__v826wp6bftszj\\TranslucentTB.exe      N/A      |\n",
      "|    0   N/A  N/A     20872    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     23076    C+G   ...es (x86)\\MSI\\Fast Boot\\FastBoot.exe      N/A      |\n",
      "|    0   N/A  N/A     23328    C+G   ...38.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     23504    C+G   ...s (x86)\\MSI\\MSI X Boost\\X_Boost.exe      N/A      |\n",
      "|    0   N/A  N/A     24452    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     25384    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe      N/A      |\n",
      "|    0   N/A  N/A     25388    C+G   C:\\Windows\\System32\\svchost.exe             N/A      |\n",
      "|    0   N/A  N/A     25760    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     26208    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     31216    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cpu\n",
      "CUDA Available: False\n",
      "CUDA is not available. Check your installation.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Current CUDA Version:\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your installation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cpu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
