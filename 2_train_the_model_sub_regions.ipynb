{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.io import read_image\n",
    "import torchvision.io as io\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, resnet101, resnet50\n",
    "from torchvision.models import ResNet18_Weights, ResNet101_Weights, ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# 1) Class for using a dataset, including limiting the number of images used\n",
    "####################################\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, limit=None, augment_data = False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "        if not augment_data:\n",
    "            self.data = self.data[~self.data['is_augmented']]\n",
    "\n",
    "        if limit:  # Limit the dataset to a small number of observations\n",
    "            self.data = self.data.head(limit)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Mapping sub-region strings to integer labels\n",
    "        self.subregion_mapping = {\n",
    "            subregion: idx\n",
    "            for idx, subregion in enumerate(self.data['sub-region'].unique())\n",
    "        }\n",
    "        self.data['subregion_label'] = self.data['sub-region'].map(self.subregion_mapping)\n",
    "\n",
    "        self.missing_files = []  # List to log missing files\n",
    "\n",
    "        print(f\"Dataset initialized with {len(self.data)} samples.\")\n",
    "        print(f\"Sub-regions mapped: {self.subregion_mapping}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.root_dir + self.data.iloc[idx]['image_name']\n",
    "        if not os.path.exists(img_path):\n",
    "            self.missing_files.append(img_path)\n",
    "            #return None  # Skip this sample\n",
    "            print(img_path)\n",
    "            img_path = \"Streetview_Image_Dataset/raw/0.png\"\n",
    "\n",
    "\n",
    "        image = io.read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.data.iloc[idx]['subregion_label']\n",
    "\n",
    "        # Debug: print shape for the first item\n",
    "        # if idx == 0:\n",
    "        #     print(f\"Sample image shape: {image.shape}, Label: {label}\")\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Filter out None values\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return torch.utils.data.default_collate(batch)\n",
    "\n",
    "####################################\n",
    "# 2) TRAIN FUNCTION (with softmax)\n",
    "####################################\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # We'll store raw predictions for final column, plus softmax probabilities\n",
    "    predictions = []\n",
    "    probabilities_list = []\n",
    "\n",
    "    with tqdm(train_loader, desc=\"Training\", unit=\"batch\") as pbar:\n",
    "        for batch in pbar:\n",
    "            if batch is None:  # Skip if batch is empty\n",
    "                continue\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Predictions\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "            # Softmax probabilities\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            probabilities_list.append(probs.detach().cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Combine probabilities from all batches into one array\n",
    "    probabilities_array = np.concatenate(probabilities_list, axis=0)\n",
    "\n",
    "    train_accuracy = correct / len(train_loader.dataset)\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "\n",
    "    return avg_loss, train_accuracy, predictions, probabilities_array\n",
    "\n",
    "####################################\n",
    "# 3) TEST FUNCTION \n",
    "####################################\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    predictions = []\n",
    "    probabilities_list = []\n",
    "\n",
    "    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar:\n",
    "        for batch in pbar:\n",
    "            if batch is None:\n",
    "                continue\n",
    "\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Predictions\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "            # Softmax probabilities\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            probabilities_list.append(probs.detach().cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Combine probabilities\n",
    "    probabilities_array = np.concatenate(probabilities_list, axis=0)\n",
    "\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "\n",
    "    return avg_loss, test_accuracy, predictions, probabilities_array\n",
    "\n",
    "####################################\n",
    "# 4) SAVE EPOCH FUNCTION\n",
    "####################################\n",
    "def save_epoch(\n",
    "    model_name,\n",
    "    model,\n",
    "    train_loss,\n",
    "    test_loss,\n",
    "    train_accuracy,\n",
    "    test_accuracy,\n",
    "    train_predictions,\n",
    "    test_predictions,\n",
    "    train_probabilities,     \n",
    "    test_probabilities,      \n",
    "    train_df,\n",
    "    test_df,\n",
    "    subregion_mapping,\n",
    "    save_weights=False\n",
    "):\n",
    "    os.makedirs(f'models/{model_name}', exist_ok=True)\n",
    "\n",
    "    # Metrics DataFrame\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'train_loss': [train_loss],\n",
    "        'test_loss': [test_loss],\n",
    "        'train_accuracy': [train_accuracy],\n",
    "        'test_accuracy': [test_accuracy]\n",
    "    })\n",
    "\n",
    "    # Reverse mapping for human-readable sub-region names\n",
    "    reverse_mapping = {v: k for k, v in subregion_mapping.items()}\n",
    "\n",
    "    # Single best-label predictions\n",
    "    train_df['model_prediction'] = [reverse_mapping[pred] for pred in train_predictions]\n",
    "    test_df['model_prediction'] = [reverse_mapping[pred] for pred in test_predictions]\n",
    "\n",
    "    # Add a probability column for each sub-region (e.g., \"prob_<sub-region>\")\n",
    "    for class_idx, class_name in reverse_mapping.items():\n",
    "        col_name_train = f'prob_{class_name}'\n",
    "        col_name_test = f'prob_{class_name}'\n",
    "\n",
    "        # For each row in train_probabilities, store the probability for class_idx\n",
    "        train_df[col_name_train] = [row[class_idx] for row in train_probabilities]\n",
    "        # For test\n",
    "        test_df[col_name_test] = [row[class_idx] for row in test_probabilities]\n",
    "\n",
    "    # Save model weights if required\n",
    "    if save_weights:\n",
    "        torch.save(model.state_dict(), f'models/{model_name}/model.pth')\n",
    "\n",
    "    # Save metrics and predictions to CSV\n",
    "    metrics_df.to_csv(f\"models/{model_name}/metrics.csv\", index=False)\n",
    "    train_df.to_csv(f\"models/{model_name}/train_predictions.csv\", index=False)\n",
    "    test_df.to_csv(f\"models/{model_name}/test_predictions.csv\", index=False)\n",
    "\n",
    "####################################\n",
    "# 6) TRAIN LOOP \n",
    "####################################\n",
    "def train_loop(\n",
    "    csv_path,\n",
    "    root_dir,\n",
    "    num_epochs=2,\n",
    "    batch_size=2,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.0001,\n",
    "    limit=None,\n",
    "    resnet_=resnet18,\n",
    "    weights_=ResNet18_Weights,\n",
    "    freeze = False,\n",
    "    augment_data = False,\n",
    "    name = \"test\"\n",
    "):\n",
    "    # Prompt user for model name\n",
    "    model_name = name#input(\"Give model name: \")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Data transformations\n",
    "    weights = weights_.DEFAULT\n",
    "    transform = weights.transforms()\n",
    "\n",
    "    # Dataset\n",
    "    dataset = CustomDataset(\n",
    "        csv_file=csv_path,\n",
    "        root_dir=root_dir,\n",
    "        transform=transform,\n",
    "        limit=limit,\n",
    "        augment_data=augment_data\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Split indices for train/test\n",
    "    # train_idx, test_idx = train_test_split(\n",
    "    #     range(len(dataset)), test_size=0.2, random_state=42\n",
    "    # )\n",
    "    \n",
    "    # train_set = Subset(dataset, train_idx)\n",
    "    # test_set = Subset(dataset, test_idx)\n",
    "\n",
    "    #df = pd.read_csv(\"datadata.csv\")\n",
    "\n",
    "    train_idx = [i for i in range(len(dataset.data)) if not dataset.data.iloc[i][\"is_test\"]]\n",
    "    test_idx  = [i for i in range(len(dataset.data)) if     dataset.data.iloc[i][\"is_test\"]]\n",
    "    #print(test_idx)\n",
    "\n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # train/test DataFrames\n",
    "    train_df = dataset.data.iloc[train_idx].reset_index(drop=True)\n",
    "    test_df = dataset.data.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Training dataset size: {len(train_set)}\")\n",
    "    print(f\"Testing dataset size: {len(test_set)}\")\n",
    "\n",
    "    # Log missing files if any - this may be no longer necessary now that the file is fixed. \n",
    "    if dataset.missing_files:\n",
    "        print(f\"Missing files: {len(dataset.missing_files)}\")\n",
    "        with open('missing_files.log', 'w') as f:\n",
    "            for file in dataset.missing_files:\n",
    "                f.write(f\"{file}\\n\")\n",
    "\n",
    "    # Load chosen ResNet\n",
    "    resnet = resnet_(weights=weights_.DEFAULT)\n",
    "\n",
    "    # Freeze all layers except the last\n",
    "    if(freeze == True):\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    \n",
    "    # Modify the final FC layer\n",
    "    num_features = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(num_features, len(dataset.subregion_mapping))\n",
    "    resnet.to(device)\n",
    "\n",
    "    # Loss function & Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(resnet.fc.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    training_times = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train step (returns probabilities)\n",
    "        train_loss, train_accuracy, train_predictions, train_probabilities = train(\n",
    "            resnet, train_loader, optimizer, criterion, device\n",
    "        )\n",
    "        # Test step (returns probabilities)\n",
    "        test_loss, test_accuracy, test_predictions, test_probabilities = test(\n",
    "            resnet, test_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        training_times.append({'epoch': epoch + 1, 'training_time': epoch_time})\n",
    "\n",
    "        # Save everything for this epoch\n",
    "        save_epoch(\n",
    "            model_name, \n",
    "            resnet,\n",
    "            train_loss, \n",
    "            test_loss,\n",
    "            train_accuracy, \n",
    "            test_accuracy,\n",
    "            train_predictions,\n",
    "            test_predictions,\n",
    "            train_probabilities,   \n",
    "            test_probabilities,    \n",
    "            train_df, \n",
    "            test_df, \n",
    "            dataset.subregion_mapping,\n",
    "            save_weights=(epoch == num_epochs - 1)  # only save on last epoch\n",
    "        )\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"Epoch {epoch + 1} training time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "    # Save training times\n",
    "    training_times_df = pd.DataFrame(training_times)\n",
    "    training_times_df.to_csv(f\"models/{model_name}/training_times.csv\", index=False)\n",
    "\n",
    "    print(f\"\\nTraining complete! Model and metrics saved to /models/{model_name}.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=2,\n",
    "#     batch_size=32,  # for example\n",
    "#     resnet_=resnet18, \n",
    "#     weights_=ResNet18_Weights,\n",
    "#     limit=100,\n",
    "#     freeze=False,\n",
    "#     augment_data = False,\n",
    "#     name='test2'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Resnet 50 models \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Resnet 101 models \n",
      "\n",
      "\n",
      "Using device: cuda\n",
      "Dataset initialized with 47405 samples.\n",
      "Sub-regions mapped: {'Western Europe': 0, 'Western Asia': 1, 'Southern Europe': 2, 'Southern Asia': 3, 'Northern America': 4, 'Latin America and the Caribbean': 5, 'South-eastern Asia': 6, 'Australia and New Zealand': 7, 'Sub-Saharan Africa': 8, 'Eastern Asia': 9, 'Northern Europe': 10, 'Eastern Europe': 11, nan: 12}\n",
      "Training dataset size: 42376\n",
      "Testing dataset size: 5029\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/332 [00:32<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 164.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 112\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Resnet 101 models \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# train_loop(\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m#     csv_path='datadata.csv',\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m#     root_dir='Streetview_Image_Dataset/processed/',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m#     name='ResNet101_Augmented'\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m train_loop(\n\u001b[0;32m    113\u001b[0m     csv_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    114\u001b[0m     root_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStreetview_Image_Dataset/processed/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    115\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    116\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,  \n\u001b[0;32m    117\u001b[0m     resnet_\u001b[38;5;241m=\u001b[39mresnet101, \n\u001b[0;32m    118\u001b[0m     weights_\u001b[38;5;241m=\u001b[39mResNet101_Weights,\n\u001b[0;32m    119\u001b[0m     limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    120\u001b[0m     freeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    121\u001b[0m     augment_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNet101_Augmented_Unfrozen\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    123\u001b[0m )\n",
      "Cell \u001b[1;32mIn[7], line 314\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(csv_path, root_dir, num_epochs, batch_size, learning_rate, weight_decay, limit, resnet_, weights_, freeze, augment_data, name)\u001b[0m\n\u001b[0;32m    311\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Train step (returns probabilities)\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m train_loss, train_accuracy, train_predictions, train_probabilities \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m    315\u001b[0m     resnet, train_loader, optimizer, criterion, device\n\u001b[0;32m    316\u001b[0m )\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# Test step (returns probabilities)\u001b[39;00m\n\u001b[0;32m    318\u001b[0m test_loss, test_accuracy, test_predictions, test_probabilities \u001b[38;5;241m=\u001b[39m test(\n\u001b[0;32m    319\u001b[0m     resnet, test_loader, criterion, device\n\u001b[0;32m    320\u001b[0m )\n",
      "Cell \u001b[1;32mIn[7], line 79\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     76\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 79\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     80\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     81\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:154\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m--> 154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n\u001b[0;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\user1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 22.13 GiB is allocated by PyTorch, and 164.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=4,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet18, \n",
    "#     weights_=ResNet18_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=True,\n",
    "#     augment_data = False,\n",
    "#     name='ResNet18'\n",
    "# )\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=4,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet18, \n",
    "#     weights_=ResNet18_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=True,\n",
    "#     augment_data = True,\n",
    "#     name='ResNet18_Augmented'\n",
    "# )\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=4,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet18, \n",
    "#     weights_=ResNet18_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=False,\n",
    "#     augment_data = True,\n",
    "#     name='ResNet18_Augmented_Unfrozen'\n",
    "# )\n",
    "\n",
    "\n",
    "####\n",
    "print(\"\\n\\n Resnet 50 models \\n\\n\")\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=4,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet50, \n",
    "#     weights_=ResNet50_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=True,\n",
    "#     augment_data = False,\n",
    "#     name='ResNet50'\n",
    "# )\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=4,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet50, \n",
    "#     weights_=ResNet50_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=True,\n",
    "#     augment_data = True,\n",
    "#     name='ResNet50_Augmented'\n",
    "# )\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=1,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet50, \n",
    "#     weights_=ResNet50_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=False,\n",
    "#     augment_data = True,\n",
    "#     name='ResNet50_Augmented_Unfrozen'\n",
    "# )\n",
    "\n",
    "####\n",
    "print(\"\\n\\n Resnet 101 models \\n\\n\")\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=4,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet101, \n",
    "#     weights_=ResNet101_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=True,\n",
    "#     augment_data = False,\n",
    "#     name='ResNet101'\n",
    "# )\n",
    "\n",
    "# train_loop(\n",
    "#     csv_path='datadata.csv',\n",
    "#     root_dir='Streetview_Image_Dataset/processed/',\n",
    "#     num_epochs=1,\n",
    "#     batch_size=128,  \n",
    "#     resnet_=resnet101, \n",
    "#     weights_=ResNet101_Weights,\n",
    "#     limit=None,\n",
    "#     freeze=True,\n",
    "#     augment_data = True,\n",
    "#     name='ResNet101_Augmented'\n",
    "# )\n",
    "\n",
    "train_loop(\n",
    "    csv_path='datadata.csv',\n",
    "    root_dir='Streetview_Image_Dataset/processed/',\n",
    "    num_epochs=1,\n",
    "    batch_size=128,  \n",
    "    resnet_=resnet101, \n",
    "    weights_=ResNet101_Weights,\n",
    "    limit=None,\n",
    "    freeze=False,\n",
    "    augment_data = True,\n",
    "    name='ResNet101_Augmented_Unfrozen'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
